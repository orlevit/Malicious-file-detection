{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "07ee10dc-9396-4ca0-b97f-17c5a75fb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "DATA_DIR = os.path.join(CURR_DIR, 'data')\n",
    "PROCESSED_FILE_NAME = os.path.join(DATA_DIR, 'processed_data.pickle')\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open(PROCESSED_FILE_NAME, 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "\n",
    "X_train = data_dict['X_train']\n",
    "X_test = data_dict['X_test']\n",
    "y_train = data_dict['y_train']\n",
    "y_test = data_dict['y_test']\n",
    "\n",
    "RANDOM_CV_SPLIT = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=RANDOM_CV_SPLIT, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87a39130-a48c-47d9-919e-b0d90ca26965",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('classifier', AdaBoostClassifier())])\n",
    "\n",
    "# RandomForestClassifier\n",
    "RandomForestClassifier_param = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [50, 100],         \n",
    "    'classifier__max_depth': [5, 10],                  \n",
    "    'classifier__class_weight': ['balanced'],          \n",
    "    'classifier__min_samples_split': [2, 5],           \n",
    "    'classifier__min_samples_leaf': [1, 2],           \n",
    "    'classifier__random_state': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "# AdaBoostClassifier\n",
    "AdaBoost_param = {\n",
    "    'classifier': [AdaBoostClassifier(algorithm='SAMME')],\n",
    "    'classifier__n_estimators': [50, 100],             \n",
    "    'classifier__learning_rate': [0.5, 1],             \n",
    "    'classifier__random_state': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "# XGBClassifier\n",
    "XGBClassifier_param = {\n",
    "    'classifier': [xgb.XGBClassifier()],\n",
    "    'classifier__eta': [0.05, 0.1],                 \n",
    "    'classifier__gamma': [0.5, 1.5],               \n",
    "    'classifier__max_depth': [4, 6],                   \n",
    "    'classifier__subsample': [0.8, 1.0],               \n",
    "    'classifier__min_child_weight': [1],              \n",
    "    'classifier__eval_metric': ['mlogloss'],\n",
    "    'classifier__seed': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "params = [AdaBoost_param, XGBClassifier_param, RandomForestClassifier_param]\n",
    "\n",
    "gs = GridSearchCV(pipeline, param_grid=params, refit='f1', return_train_score=True, cv=cv_strategy, n_jobs=-1, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ec124fe2-373e-4972-8212-9750874d95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "columns_to_encode = ['f_0','f_1','f_2','f_4','f_6','f_8','f_9','f_14', 'f_41','f_42','f_43','f_44','f_45','f_46','f_47','f_48','f_49', 'f_59', 'f_68_outlier', 'f_70_outlier', 'f_74_outlier', 'f_83_outlier', 'f_87_outlier', 'f_2_no_signature','f_9_no_signature']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoders_train = {col: LabelEncoder() for col in columns_to_encode}\n",
    "label_encoders_test = {col: LabelEncoder() for col in columns_to_encode}\n",
    "\n",
    "# Function to apply label encoding to the specified columns\n",
    "def encode_columns(df, columns, encoders):\n",
    "    for col in columns:\n",
    "        if col in df.columns:  # Check if the column exists in the DataFrame\n",
    "            df[col] = encoders[col].fit_transform(df[col].astype(str))  # Convert values to strings and encode\n",
    "\n",
    "# Apply encoding to X_train and X_test\n",
    "encode_columns(X_train_encoded, columns_to_encode, label_encoders_train)\n",
    "encode_columns(X_test_encoded, columns_to_encode, label_encoders_test)\n",
    "\n",
    "X_train_encoded = X_train_encoded.drop(['Unnamed: 0', 'broccoli_encoded', 'broccoli'], axis=1)\n",
    "X_test_encoded = X_test_encoded.drop(['Unnamed: 0', 'broccoli_encoded', 'broccoli'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e376b99d-0f17-4df2-8695-8cfa615c166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (47984, 110)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/or/dev/malicious_files_detection/mfd/lib/python3.12/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV time(mintues): 18.83\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "print('df_train shape:',X_train_encoded.shape)\n",
    "gs.fit(X_train_encoded, y_train)\n",
    "toc = time()\n",
    "print(f'GridSearchCV time(mintues): {round((toc-tic)/60,2)}')\n",
    "\n",
    "best_params = gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d9c9910c-112b-49d4-970c-a8a76de05e25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__eta</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.692948</td>\n",
       "      <td>4.969483</td>\n",
       "      <td>0.326343</td>\n",
       "      <td>0.278031</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793473</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>36</td>\n",
       "      <td>0.793446</td>\n",
       "      <td>0.794201</td>\n",
       "      <td>0.791596</td>\n",
       "      <td>0.794410</td>\n",
       "      <td>0.800380</td>\n",
       "      <td>0.794807</td>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.257860</td>\n",
       "      <td>2.356325</td>\n",
       "      <td>0.354144</td>\n",
       "      <td>0.156017</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803518</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>34</td>\n",
       "      <td>0.802277</td>\n",
       "      <td>0.808034</td>\n",
       "      <td>0.806002</td>\n",
       "      <td>0.800219</td>\n",
       "      <td>0.807205</td>\n",
       "      <td>0.804747</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.562062</td>\n",
       "      <td>1.443313</td>\n",
       "      <td>0.185705</td>\n",
       "      <td>0.082922</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801913</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>35</td>\n",
       "      <td>0.810352</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.798057</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>0.803663</td>\n",
       "      <td>0.803950</td>\n",
       "      <td>0.003898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.494480</td>\n",
       "      <td>1.373331</td>\n",
       "      <td>0.235110</td>\n",
       "      <td>0.015296</td>\n",
       "      <td>AdaBoostClassifier(algorithm='SAMME')</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809103</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>25</td>\n",
       "      <td>0.818220</td>\n",
       "      <td>0.813270</td>\n",
       "      <td>0.801495</td>\n",
       "      <td>0.809884</td>\n",
       "      <td>0.813562</td>\n",
       "      <td>0.811286</td>\n",
       "      <td>0.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.119313</td>\n",
       "      <td>1.161037</td>\n",
       "      <td>0.327451</td>\n",
       "      <td>0.377618</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859536</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>22</td>\n",
       "      <td>0.861646</td>\n",
       "      <td>0.864329</td>\n",
       "      <td>0.868992</td>\n",
       "      <td>0.862714</td>\n",
       "      <td>0.866703</td>\n",
       "      <td>0.864877</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.481230</td>\n",
       "      <td>3.005825</td>\n",
       "      <td>0.168070</td>\n",
       "      <td>0.043722</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859474</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>23</td>\n",
       "      <td>0.863886</td>\n",
       "      <td>0.862896</td>\n",
       "      <td>0.867377</td>\n",
       "      <td>0.862271</td>\n",
       "      <td>0.865010</td>\n",
       "      <td>0.864288</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.188290</td>\n",
       "      <td>1.711053</td>\n",
       "      <td>0.190363</td>\n",
       "      <td>0.085198</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885503</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>6</td>\n",
       "      <td>0.895251</td>\n",
       "      <td>0.896762</td>\n",
       "      <td>0.898247</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.896817</td>\n",
       "      <td>0.896393</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.233853</td>\n",
       "      <td>1.080822</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883128</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>8</td>\n",
       "      <td>0.894287</td>\n",
       "      <td>0.894496</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.895199</td>\n",
       "      <td>0.896765</td>\n",
       "      <td>0.895126</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.155534</td>\n",
       "      <td>1.029478</td>\n",
       "      <td>0.136063</td>\n",
       "      <td>0.052634</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>21</td>\n",
       "      <td>0.863938</td>\n",
       "      <td>0.864277</td>\n",
       "      <td>0.867794</td>\n",
       "      <td>0.863261</td>\n",
       "      <td>0.866703</td>\n",
       "      <td>0.865195</td>\n",
       "      <td>0.001743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.576718</td>\n",
       "      <td>0.256176</td>\n",
       "      <td>0.103719</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858244</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>24</td>\n",
       "      <td>0.863443</td>\n",
       "      <td>0.860995</td>\n",
       "      <td>0.866700</td>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.864072</td>\n",
       "      <td>0.863491</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.120147</td>\n",
       "      <td>0.232868</td>\n",
       "      <td>0.134681</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885712</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895303</td>\n",
       "      <td>0.896371</td>\n",
       "      <td>0.899159</td>\n",
       "      <td>0.895720</td>\n",
       "      <td>0.897025</td>\n",
       "      <td>0.896716</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.390306</td>\n",
       "      <td>0.224672</td>\n",
       "      <td>0.108512</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884503</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>7</td>\n",
       "      <td>0.893506</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.895173</td>\n",
       "      <td>0.895980</td>\n",
       "      <td>0.897207</td>\n",
       "      <td>0.895491</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.457981</td>\n",
       "      <td>0.333924</td>\n",
       "      <td>0.123283</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877668</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>9</td>\n",
       "      <td>0.884127</td>\n",
       "      <td>0.886133</td>\n",
       "      <td>0.885612</td>\n",
       "      <td>0.883268</td>\n",
       "      <td>0.887960</td>\n",
       "      <td>0.885420</td>\n",
       "      <td>0.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.339755</td>\n",
       "      <td>0.276829</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875813</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>12</td>\n",
       "      <td>0.883476</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.884075</td>\n",
       "      <td>0.884414</td>\n",
       "      <td>0.883636</td>\n",
       "      <td>0.883560</td>\n",
       "      <td>0.000756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.912880</td>\n",
       "      <td>0.141748</td>\n",
       "      <td>0.104371</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898612</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916430</td>\n",
       "      <td>0.915570</td>\n",
       "      <td>0.915128</td>\n",
       "      <td>0.913877</td>\n",
       "      <td>0.916120</td>\n",
       "      <td>0.915425</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.834056</td>\n",
       "      <td>1.207538</td>\n",
       "      <td>0.136241</td>\n",
       "      <td>0.036374</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896924</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914841</td>\n",
       "      <td>0.913434</td>\n",
       "      <td>0.915883</td>\n",
       "      <td>0.914711</td>\n",
       "      <td>0.913228</td>\n",
       "      <td>0.914419</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.272393</td>\n",
       "      <td>0.175095</td>\n",
       "      <td>0.092398</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877542</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885169</td>\n",
       "      <td>0.884075</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>0.883997</td>\n",
       "      <td>0.885798</td>\n",
       "      <td>0.885014</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.363592</td>\n",
       "      <td>0.368413</td>\n",
       "      <td>0.111611</td>\n",
       "      <td>0.041331</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>13</td>\n",
       "      <td>0.881210</td>\n",
       "      <td>0.883528</td>\n",
       "      <td>0.882903</td>\n",
       "      <td>0.883632</td>\n",
       "      <td>0.884469</td>\n",
       "      <td>0.883149</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.298690</td>\n",
       "      <td>0.381338</td>\n",
       "      <td>0.120628</td>\n",
       "      <td>0.033201</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898549</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>2</td>\n",
       "      <td>0.915336</td>\n",
       "      <td>0.915961</td>\n",
       "      <td>0.917029</td>\n",
       "      <td>0.914867</td>\n",
       "      <td>0.917266</td>\n",
       "      <td>0.916092</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.480158</td>\n",
       "      <td>0.655469</td>\n",
       "      <td>0.129324</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897841</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>3</td>\n",
       "      <td>0.915049</td>\n",
       "      <td>0.911611</td>\n",
       "      <td>0.916925</td>\n",
       "      <td>0.914476</td>\n",
       "      <td>0.914166</td>\n",
       "      <td>0.914445</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.873909</td>\n",
       "      <td>0.398028</td>\n",
       "      <td>0.050790</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805664</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>31</td>\n",
       "      <td>0.801209</td>\n",
       "      <td>0.812072</td>\n",
       "      <td>0.811473</td>\n",
       "      <td>0.804543</td>\n",
       "      <td>0.810436</td>\n",
       "      <td>0.807946</td>\n",
       "      <td>0.004304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.480652</td>\n",
       "      <td>0.371352</td>\n",
       "      <td>0.090889</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805706</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>28</td>\n",
       "      <td>0.801573</td>\n",
       "      <td>0.810926</td>\n",
       "      <td>0.812280</td>\n",
       "      <td>0.806549</td>\n",
       "      <td>0.807284</td>\n",
       "      <td>0.807722</td>\n",
       "      <td>0.003753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.704616</td>\n",
       "      <td>0.230683</td>\n",
       "      <td>0.061025</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805539</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>32</td>\n",
       "      <td>0.801026</td>\n",
       "      <td>0.809571</td>\n",
       "      <td>0.809128</td>\n",
       "      <td>0.806862</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.807165</td>\n",
       "      <td>0.003216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.054363</td>\n",
       "      <td>0.511295</td>\n",
       "      <td>0.086918</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806790</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>26</td>\n",
       "      <td>0.803710</td>\n",
       "      <td>0.810952</td>\n",
       "      <td>0.812306</td>\n",
       "      <td>0.809180</td>\n",
       "      <td>0.808273</td>\n",
       "      <td>0.808884</td>\n",
       "      <td>0.002940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.423144</td>\n",
       "      <td>0.183953</td>\n",
       "      <td>0.045126</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805414</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>33</td>\n",
       "      <td>0.804830</td>\n",
       "      <td>0.806810</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>0.806966</td>\n",
       "      <td>0.809263</td>\n",
       "      <td>0.807660</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.785254</td>\n",
       "      <td>0.225441</td>\n",
       "      <td>0.080485</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805789</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>27</td>\n",
       "      <td>0.800818</td>\n",
       "      <td>0.809831</td>\n",
       "      <td>0.812775</td>\n",
       "      <td>0.810014</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.808170</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.425057</td>\n",
       "      <td>0.195536</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805685</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>30</td>\n",
       "      <td>0.803970</td>\n",
       "      <td>0.806810</td>\n",
       "      <td>0.808920</td>\n",
       "      <td>0.807669</td>\n",
       "      <td>0.809446</td>\n",
       "      <td>0.807363</td>\n",
       "      <td>0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.752417</td>\n",
       "      <td>0.250051</td>\n",
       "      <td>0.100285</td>\n",
       "      <td>0.035881</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805706</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>29</td>\n",
       "      <td>0.801912</td>\n",
       "      <td>0.809988</td>\n",
       "      <td>0.812254</td>\n",
       "      <td>0.809858</td>\n",
       "      <td>0.807674</td>\n",
       "      <td>0.808337</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.316478</td>\n",
       "      <td>0.591002</td>\n",
       "      <td>0.107992</td>\n",
       "      <td>0.039422</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874146</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>18</td>\n",
       "      <td>0.888660</td>\n",
       "      <td>0.892724</td>\n",
       "      <td>0.890171</td>\n",
       "      <td>0.891161</td>\n",
       "      <td>0.893691</td>\n",
       "      <td>0.891281</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.025560</td>\n",
       "      <td>0.772129</td>\n",
       "      <td>0.222364</td>\n",
       "      <td>0.148297</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>17</td>\n",
       "      <td>0.888999</td>\n",
       "      <td>0.891917</td>\n",
       "      <td>0.891135</td>\n",
       "      <td>0.892568</td>\n",
       "      <td>0.891320</td>\n",
       "      <td>0.891188</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.676675</td>\n",
       "      <td>2.211444</td>\n",
       "      <td>0.153499</td>\n",
       "      <td>0.067923</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874375</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>16</td>\n",
       "      <td>0.889494</td>\n",
       "      <td>0.889624</td>\n",
       "      <td>0.891500</td>\n",
       "      <td>0.886785</td>\n",
       "      <td>0.890591</td>\n",
       "      <td>0.889599</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.120009</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.161804</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>19</td>\n",
       "      <td>0.890848</td>\n",
       "      <td>0.890901</td>\n",
       "      <td>0.891604</td>\n",
       "      <td>0.888009</td>\n",
       "      <td>0.889966</td>\n",
       "      <td>0.890266</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.661701</td>\n",
       "      <td>3.295554</td>\n",
       "      <td>0.109316</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874937</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>14</td>\n",
       "      <td>0.889702</td>\n",
       "      <td>0.887983</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>0.889077</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.889552</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.275228</td>\n",
       "      <td>0.791290</td>\n",
       "      <td>0.159440</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876105</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>11</td>\n",
       "      <td>0.889806</td>\n",
       "      <td>0.889754</td>\n",
       "      <td>0.891474</td>\n",
       "      <td>0.889624</td>\n",
       "      <td>0.891581</td>\n",
       "      <td>0.890448</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.508404</td>\n",
       "      <td>0.353371</td>\n",
       "      <td>0.074769</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873958</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>20</td>\n",
       "      <td>0.890093</td>\n",
       "      <td>0.889572</td>\n",
       "      <td>0.891109</td>\n",
       "      <td>0.886785</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.889578</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8.914763</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.147023</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874917</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>15</td>\n",
       "      <td>0.890380</td>\n",
       "      <td>0.889025</td>\n",
       "      <td>0.890666</td>\n",
       "      <td>0.889416</td>\n",
       "      <td>0.891112</td>\n",
       "      <td>0.890120</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       13.692948      4.969483         0.326343        0.278031   \n",
       "1       18.257860      2.356325         0.354144        0.156017   \n",
       "2        9.562062      1.443313         0.185705        0.082922   \n",
       "3       15.494480      1.373331         0.235110        0.015296   \n",
       "4        3.119313      1.161037         0.327451        0.377618   \n",
       "5        5.481230      3.005825         0.168070        0.043722   \n",
       "6        5.188290      1.711053         0.190363        0.085198   \n",
       "7        4.233853      1.080822         0.115300        0.012420   \n",
       "8        3.155534      1.029478         0.136063        0.052634   \n",
       "9        2.576718      0.256176         0.103719        0.014925   \n",
       "10       4.120147      0.232868         0.134681        0.021415   \n",
       "11       3.390306      0.224672         0.108512        0.011205   \n",
       "12       2.457981      0.333924         0.123283        0.042160   \n",
       "13       2.339755      0.276829         0.088854        0.006939   \n",
       "14       2.912880      0.141748         0.104371        0.011331   \n",
       "15       3.834056      1.207538         0.136241        0.036374   \n",
       "16       2.272393      0.175095         0.092398        0.016129   \n",
       "17       2.363592      0.368413         0.111611        0.041331   \n",
       "18       3.298690      0.381338         0.120628        0.033201   \n",
       "19       3.480158      0.655469         0.129324        0.010511   \n",
       "20       2.873909      0.398028         0.050790        0.002653   \n",
       "21       5.480652      0.371352         0.090889        0.013926   \n",
       "22       2.704616      0.230683         0.061025        0.027951   \n",
       "23       5.054363      0.511295         0.086918        0.011245   \n",
       "24       2.423144      0.183953         0.045126        0.006966   \n",
       "25       4.785254      0.225441         0.080485        0.010554   \n",
       "26       2.425057      0.195536         0.047862        0.007772   \n",
       "27       4.752417      0.250051         0.100285        0.035881   \n",
       "28       5.316478      0.591002         0.107992        0.039422   \n",
       "29      10.025560      0.772129         0.222364        0.148297   \n",
       "30       7.676675      2.211444         0.153499        0.067923   \n",
       "31      10.120009      0.496933         0.161804        0.007234   \n",
       "32       6.661701      3.295554         0.109316        0.030819   \n",
       "33      10.275228      0.791290         0.159440        0.019766   \n",
       "34       4.508404      0.353371         0.074769        0.003962   \n",
       "35       8.914763      0.088599         0.147023        0.005840   \n",
       "\n",
       "                                     param_classifier  \\\n",
       "0               AdaBoostClassifier(algorithm='SAMME')   \n",
       "1               AdaBoostClassifier(algorithm='SAMME')   \n",
       "2               AdaBoostClassifier(algorithm='SAMME')   \n",
       "3               AdaBoostClassifier(algorithm='SAMME')   \n",
       "4   XGBClassifier(base_score=None, booster=None, c...   \n",
       "5   XGBClassifier(base_score=None, booster=None, c...   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8   XGBClassifier(base_score=None, booster=None, c...   \n",
       "9   XGBClassifier(base_score=None, booster=None, c...   \n",
       "10  XGBClassifier(base_score=None, booster=None, c...   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "12  XGBClassifier(base_score=None, booster=None, c...   \n",
       "13  XGBClassifier(base_score=None, booster=None, c...   \n",
       "14  XGBClassifier(base_score=None, booster=None, c...   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16  XGBClassifier(base_score=None, booster=None, c...   \n",
       "17  XGBClassifier(base_score=None, booster=None, c...   \n",
       "18  XGBClassifier(base_score=None, booster=None, c...   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "20                           RandomForestClassifier()   \n",
       "21                           RandomForestClassifier()   \n",
       "22                           RandomForestClassifier()   \n",
       "23                           RandomForestClassifier()   \n",
       "24                           RandomForestClassifier()   \n",
       "25                           RandomForestClassifier()   \n",
       "26                           RandomForestClassifier()   \n",
       "27                           RandomForestClassifier()   \n",
       "28                           RandomForestClassifier()   \n",
       "29                           RandomForestClassifier()   \n",
       "30                           RandomForestClassifier()   \n",
       "31                           RandomForestClassifier()   \n",
       "32                           RandomForestClassifier()   \n",
       "33                           RandomForestClassifier()   \n",
       "34                           RandomForestClassifier()   \n",
       "35                           RandomForestClassifier()   \n",
       "\n",
       "    param_classifier__learning_rate  param_classifier__n_estimators  \\\n",
       "0                               0.5                            50.0   \n",
       "1                               0.5                           100.0   \n",
       "2                               1.0                            50.0   \n",
       "3                               1.0                           100.0   \n",
       "4                               NaN                             NaN   \n",
       "5                               NaN                             NaN   \n",
       "6                               NaN                             NaN   \n",
       "7                               NaN                             NaN   \n",
       "8                               NaN                             NaN   \n",
       "9                               NaN                             NaN   \n",
       "10                              NaN                             NaN   \n",
       "11                              NaN                             NaN   \n",
       "12                              NaN                             NaN   \n",
       "13                              NaN                             NaN   \n",
       "14                              NaN                             NaN   \n",
       "15                              NaN                             NaN   \n",
       "16                              NaN                             NaN   \n",
       "17                              NaN                             NaN   \n",
       "18                              NaN                             NaN   \n",
       "19                              NaN                             NaN   \n",
       "20                              NaN                            50.0   \n",
       "21                              NaN                           100.0   \n",
       "22                              NaN                            50.0   \n",
       "23                              NaN                           100.0   \n",
       "24                              NaN                            50.0   \n",
       "25                              NaN                           100.0   \n",
       "26                              NaN                            50.0   \n",
       "27                              NaN                           100.0   \n",
       "28                              NaN                            50.0   \n",
       "29                              NaN                           100.0   \n",
       "30                              NaN                            50.0   \n",
       "31                              NaN                           100.0   \n",
       "32                              NaN                            50.0   \n",
       "33                              NaN                           100.0   \n",
       "34                              NaN                            50.0   \n",
       "35                              NaN                           100.0   \n",
       "\n",
       "    param_classifier__random_state  param_classifier__eta  \\\n",
       "0                             42.0                    NaN   \n",
       "1                             42.0                    NaN   \n",
       "2                             42.0                    NaN   \n",
       "3                             42.0                    NaN   \n",
       "4                              NaN                   0.05   \n",
       "5                              NaN                   0.05   \n",
       "6                              NaN                   0.05   \n",
       "7                              NaN                   0.05   \n",
       "8                              NaN                   0.05   \n",
       "9                              NaN                   0.05   \n",
       "10                             NaN                   0.05   \n",
       "11                             NaN                   0.05   \n",
       "12                             NaN                   0.10   \n",
       "13                             NaN                   0.10   \n",
       "14                             NaN                   0.10   \n",
       "15                             NaN                   0.10   \n",
       "16                             NaN                   0.10   \n",
       "17                             NaN                   0.10   \n",
       "18                             NaN                   0.10   \n",
       "19                             NaN                   0.10   \n",
       "20                            42.0                    NaN   \n",
       "21                            42.0                    NaN   \n",
       "22                            42.0                    NaN   \n",
       "23                            42.0                    NaN   \n",
       "24                            42.0                    NaN   \n",
       "25                            42.0                    NaN   \n",
       "26                            42.0                    NaN   \n",
       "27                            42.0                    NaN   \n",
       "28                            42.0                    NaN   \n",
       "29                            42.0                    NaN   \n",
       "30                            42.0                    NaN   \n",
       "31                            42.0                    NaN   \n",
       "32                            42.0                    NaN   \n",
       "33                            42.0                    NaN   \n",
       "34                            42.0                    NaN   \n",
       "35                            42.0                    NaN   \n",
       "\n",
       "   param_classifier__eval_metric  ...  mean_test_score  std_test_score  \\\n",
       "0                            NaN  ...         0.793473        0.004008   \n",
       "1                            NaN  ...         0.803518        0.002977   \n",
       "2                            NaN  ...         0.801913        0.005069   \n",
       "3                            NaN  ...         0.809103        0.004597   \n",
       "4                       mlogloss  ...         0.859536        0.003579   \n",
       "5                       mlogloss  ...         0.859474        0.003661   \n",
       "6                       mlogloss  ...         0.885503        0.002298   \n",
       "7                       mlogloss  ...         0.883128        0.003676   \n",
       "8                       mlogloss  ...         0.859828        0.003426   \n",
       "9                       mlogloss  ...         0.858244        0.004210   \n",
       "10                      mlogloss  ...         0.885712        0.003673   \n",
       "11                      mlogloss  ...         0.884503        0.004704   \n",
       "12                      mlogloss  ...         0.877668        0.003837   \n",
       "13                      mlogloss  ...         0.875813        0.005485   \n",
       "14                      mlogloss  ...         0.898612        0.003137   \n",
       "15                      mlogloss  ...         0.896924        0.002872   \n",
       "16                      mlogloss  ...         0.877542        0.003918   \n",
       "17                      mlogloss  ...         0.875750        0.004416   \n",
       "18                      mlogloss  ...         0.898549        0.002872   \n",
       "19                      mlogloss  ...         0.897841        0.003173   \n",
       "20                           NaN  ...         0.805664        0.002094   \n",
       "21                           NaN  ...         0.805706        0.003771   \n",
       "22                           NaN  ...         0.805539        0.002860   \n",
       "23                           NaN  ...         0.806790        0.003689   \n",
       "24                           NaN  ...         0.805414        0.003415   \n",
       "25                           NaN  ...         0.805789        0.004731   \n",
       "26                           NaN  ...         0.805685        0.003469   \n",
       "27                           NaN  ...         0.805706        0.004281   \n",
       "28                           NaN  ...         0.874146        0.003579   \n",
       "29                           NaN  ...         0.874312        0.003945   \n",
       "30                           NaN  ...         0.874375        0.003030   \n",
       "31                           NaN  ...         0.874125        0.003346   \n",
       "32                           NaN  ...         0.874937        0.002921   \n",
       "33                           NaN  ...         0.876105        0.003397   \n",
       "34                           NaN  ...         0.873958        0.003244   \n",
       "35                           NaN  ...         0.874917        0.003278   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                36            0.793446            0.794201   \n",
       "1                34            0.802277            0.808034   \n",
       "2                35            0.810352            0.803579   \n",
       "3                25            0.818220            0.813270   \n",
       "4                22            0.861646            0.864329   \n",
       "5                23            0.863886            0.862896   \n",
       "6                 6            0.895251            0.896762   \n",
       "7                 8            0.894287            0.894496   \n",
       "8                21            0.863938            0.864277   \n",
       "9                24            0.863443            0.860995   \n",
       "10                5            0.895303            0.896371   \n",
       "11                7            0.893506            0.895590   \n",
       "12                9            0.884127            0.886133   \n",
       "13               12            0.883476            0.882200   \n",
       "14                1            0.916430            0.915570   \n",
       "15                4            0.914841            0.913434   \n",
       "16               10            0.885169            0.884075   \n",
       "17               13            0.881210            0.883528   \n",
       "18                2            0.915336            0.915961   \n",
       "19                3            0.915049            0.911611   \n",
       "20               31            0.801209            0.812072   \n",
       "21               28            0.801573            0.810926   \n",
       "22               32            0.801026            0.809571   \n",
       "23               26            0.803710            0.810952   \n",
       "24               33            0.804830            0.806810   \n",
       "25               27            0.800818            0.809831   \n",
       "26               30            0.803970            0.806810   \n",
       "27               29            0.801912            0.809988   \n",
       "28               18            0.888660            0.892724   \n",
       "29               17            0.888999            0.891917   \n",
       "30               16            0.889494            0.889624   \n",
       "31               19            0.890848            0.890901   \n",
       "32               14            0.889702            0.887983   \n",
       "33               11            0.889806            0.889754   \n",
       "34               20            0.890093            0.889572   \n",
       "35               15            0.890380            0.889025   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.791596            0.794410            0.800380   \n",
       "1            0.806002            0.800219            0.807205   \n",
       "2            0.798057            0.804100            0.803663   \n",
       "3            0.801495            0.809884            0.813562   \n",
       "4            0.868992            0.862714            0.866703   \n",
       "5            0.867377            0.862271            0.865010   \n",
       "6            0.898247            0.894886            0.896817   \n",
       "7            0.894886            0.895199            0.896765   \n",
       "8            0.867794            0.863261            0.866703   \n",
       "9            0.866700            0.862245            0.864072   \n",
       "10           0.899159            0.895720            0.897025   \n",
       "11           0.895173            0.895980            0.897207   \n",
       "12           0.885612            0.883268            0.887960   \n",
       "13           0.884075            0.884414            0.883636   \n",
       "14           0.915128            0.913877            0.916120   \n",
       "15           0.915883            0.914711            0.913228   \n",
       "16           0.886029            0.883997            0.885798   \n",
       "17           0.882903            0.883632            0.884469   \n",
       "18           0.917029            0.914867            0.917266   \n",
       "19           0.916925            0.914476            0.914166   \n",
       "20           0.811473            0.804543            0.810436   \n",
       "21           0.812280            0.806549            0.807284   \n",
       "22           0.809128            0.806862            0.809237   \n",
       "23           0.812306            0.809180            0.808273   \n",
       "24           0.810431            0.806966            0.809263   \n",
       "25           0.812775            0.810014            0.807414   \n",
       "26           0.808920            0.807669            0.809446   \n",
       "27           0.812254            0.809858            0.807674   \n",
       "28           0.890171            0.891161            0.893691   \n",
       "29           0.891135            0.892568            0.891320   \n",
       "30           0.891500            0.886785            0.890591   \n",
       "31           0.891604            0.888009            0.889966   \n",
       "32           0.890666            0.889077            0.890330   \n",
       "33           0.891474            0.889624            0.891581   \n",
       "34           0.891109            0.886785            0.890330   \n",
       "35           0.890666            0.889416            0.891112   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.794807         0.002958  \n",
       "1          0.804747         0.003001  \n",
       "2          0.803950         0.003898  \n",
       "3          0.811286         0.005568  \n",
       "4          0.864877         0.002672  \n",
       "5          0.864288         0.001802  \n",
       "6          0.896393         0.001211  \n",
       "7          0.895126         0.000877  \n",
       "8          0.865195         0.001743  \n",
       "9          0.863491         0.001919  \n",
       "10         0.896716         0.001354  \n",
       "11         0.895491         0.001203  \n",
       "12         0.885420         0.001631  \n",
       "13         0.883560         0.000756  \n",
       "14         0.915425         0.000894  \n",
       "15         0.914419         0.000979  \n",
       "16         0.885014         0.000847  \n",
       "17         0.883149         0.001090  \n",
       "18         0.916092         0.000932  \n",
       "19         0.914445         0.001710  \n",
       "20         0.807946         0.004304  \n",
       "21         0.807722         0.003753  \n",
       "22         0.807165         0.003216  \n",
       "23         0.808884         0.002940  \n",
       "24         0.807660         0.001973  \n",
       "25         0.808170         0.004049  \n",
       "26         0.807363         0.001932  \n",
       "27         0.808337         0.003524  \n",
       "28         0.891281         0.001789  \n",
       "29         0.891188         0.001204  \n",
       "30         0.889599         0.001583  \n",
       "31         0.890266         0.001242  \n",
       "32         0.889552         0.000955  \n",
       "33         0.890448         0.000884  \n",
       "34         0.889578         0.001482  \n",
       "35         0.890120         0.000780  \n",
       "\n",
       "[36 rows x 34 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1f75b2ff-c4c4-4e0a-bfa9-a35ab47cc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.898612052371688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eta=0.1,\n",
       "                               eval_metric=&#x27;mlogloss&#x27;, feature_types=None,\n",
       "                               gamma=0.5, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None, min_child_weight=1,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=None,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eta=0.1,\n",
       "                               eval_metric=&#x27;mlogloss&#x27;, feature_types=None,\n",
       "                               gamma=0.5, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None, min_child_weight=1,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=None,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=0.5, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('classifier',\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, device=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eta=0.1,\n",
       "                               eval_metric='mlogloss', feature_types=None,\n",
       "                               gamma=0.5, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=6, max_leaves=None, min_child_weight=1,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=None,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Best score: {gs.best_score_}\")\n",
    "best_model = gs.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "33ad491f-43d4-4399-95b5-a2f85535a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------- All features importance --------------------------\n",
      "    Feature  Importance\n",
      "58     f_59    0.354940\n",
      "36     f_37    0.033018\n",
      "41     f_42    0.032921\n",
      "2       f_2    0.029512\n",
      "102   f_103    0.022611\n",
      " -------------------------- Found correlated features importance --------------------------\n",
      "            Feature  Importance  Position\n",
      "0              f_59    0.354940         0\n",
      "1  f_2_no_signature    0.006145        38\n",
      "2      f_70_outlier    0.000000       104\n",
      "3      f_68_outlier    0.000000       105\n",
      "4      f_74_outlier    0.000000       106\n",
      "5      f_83_outlier    0.000000       107\n",
      "6      f_87_outlier    0.000000       108\n",
      "7  f_9_no_signature    0.000000       109\n"
     ]
    }
   ],
   "source": [
    "importances = best_model['classifier'].feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_encoded.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "target_features = ['f_59','f_68_outlier', 'f_70_outlier', 'f_74_outlier', 'f_83_outlier', 'f_87_outlier', 'f_2_no_signature','f_9_no_signature']\n",
    "found_features = importance_df[importance_df['Feature'].isin(target_features)]\n",
    "\n",
    "positions = {feature: importance_df.index.get_loc(importance_df[importance_df['Feature'] == feature].index[0])\n",
    "             for feature in target_features if feature in importance_df['Feature'].values}\n",
    "positions_df = pd.DataFrame(list(positions.items()), columns=['Feature', 'Position'])\n",
    "combined_df = pd.merge(importance_df, positions_df, on='Feature')\n",
    "\n",
    "print(' -------------------------- All features importance --------------------------')\n",
    "print(importance_df.iloc[:5])\n",
    "\n",
    "#found_features\n",
    "print(' -------------------------- Found correlated features importance --------------------------')\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb856614-72d2-45b9-9654-d5880bb4aa90",
   "metadata": {},
   "source": [
    "### Surprsingly, only two found features are relatively important - f_59, f_2_no_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7924c745-f159-4951-a533-c006fa95477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train Score: 0.9133910789290367. Accuracy: 0.9146382127375792\n",
      "F1 Test Score: 0.8891068276274676. Accuracy: 0.8905468489496499\n"
     ]
    }
   ],
   "source": [
    "test_predictions = best_model.predict(X_test_encoded)\n",
    "test_f1_macro =  f1_score(y_test, test_predictions, average='macro')\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "train_predictions = best_model.predict(X_train_encoded)\n",
    "train_f1_macro =  f1_score(y_train, train_predictions, average='macro')\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "print(f'F1 Train Score: {train_f1_macro}. Accuracy: {train_accuracy}')\n",
    "print(f'F1 Test Score: {test_f1_macro}. Accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
